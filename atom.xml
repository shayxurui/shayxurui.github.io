<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xurui blog</title>
  
  <subtitle>blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-02T07:18:56.302Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>xu rui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>人体关键点综述</title>
    <link href="http://yoursite.com/2018/11/02/%E4%BA%BA%E4%BD%93%E5%85%B3%E9%94%AE%E7%82%B9%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2018/11/02/人体关键点综述/</id>
    <published>2018-11-02T07:11:59.000Z</published>
    <updated>2018-11-02T07:18:56.302Z</updated>
    
    <content type="html"><![CDATA[<p>人体关键点对于描述人体姿态，预测人体行为至关重要。因此人体关键点检测是诸多计算机视觉任务的基础，例如动作分类，异常行为检测，以及自动驾驶等等。近年来，随着深度学习技术的发展，人体关键点检测效果不断提升，已经开始广泛应用于计算机视觉的相关领域。本文主要介绍2D人体骨骼关键点的基本概念和相关算法，其中算法部分主要介绍基于深度学习的人体关键点检测。</p><a id="more"></a> <p>#相关数据集</p><p>##单人数据集</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;人体关键点对于描述人体姿态，预测人体行为至关重要。因此人体关键点检测是诸多计算机视觉任务的基础，例如动作分类，异常行为检测，以及自动驾驶等等。近年来，随着深度学习技术的发展，人体关键点检测效果不断提升，已经开始广泛应用于计算机视觉的相关领域。本文主要介绍2D人体骨骼关键点的基本概念和相关算法，其中算法部分主要介绍基于深度学习的人体关键点检测。&lt;/p&gt;
    
    </summary>
    
    
      <category term="human pose estimation" scheme="http://yoursite.com/tags/human-pose-estimation/"/>
    
  </entry>
  
  <entry>
    <title>人脸关键点基本操作函数</title>
    <link href="http://yoursite.com/2018/10/30/FaceAlignment/"/>
    <id>http://yoursite.com/2018/10/30/FaceAlignment/</id>
    <published>2018-10-30T12:08:28.536Z</published>
    <updated>2018-10-30T12:08:28.492Z</updated>
    
    <content type="html"><![CDATA[<p>总结关于人脸数据预处理的函数。<br><a id="more"></a> </p><p>##读取图片和关键点:<br>    image=PIL.Image.open(image_path)<br>    landmark=np.loadtxt(pts_path,skiprows=3,comments=’}’)</p><pre><code>#或者landmarks = np.genfromtxt(pts_path, skip_header=3, skip_footer=1)</code></pre><p>##根据关键点得到边界框:<br>    minx = int(landmarks[:, 0].min())<br>    miny = int(landmarks[:, 1].min())<br>    maxx = int(landmarks[:, 0].max())<br>    maxy = int(landmarks[:, 1].max())    </p><p>##随机裁剪图片:<br>    h, w = image.shape[:2]<br>    new_h, new_w = output_size</p><pre><code>top = np.random.randint(0, h - new_h)left = np.random.randint(0, w - new_w)image = image[top: top + new_h,left: left + new_w]landmarks = landmarks - [left, top]</code></pre><p>##提取人脸:<br>    image = image.crop([bbox[0] - pad, bbox[1] - pad, bbox[2] + pad, bbox[3] + pad])<br>    landmarks = landmarks - (bbox[0] - pad, bbox[1] - pad)</p><blockquote><p>bbox是边界框坐标,bbox=(minx,miny,maxx,maxy).<br>pad是多裁剪部分,关键点减去裁剪后的起始坐标.</p></blockquote><p>##得到旋转矩阵:<br>    theta = np.radians(rotation_angle)<br>    c, s = np.cos(theta), np.sin(theta)<br>    mat = np.matrix(‘{} {} 0; {} {} 0’.format(c, -s, s, c), np.float32)</p><blockquote><p>mat=((cos,-sin,0),(sin,cos,0))</p></blockquote><p>##随机旋转图片:<br>    w, h = image.size<br>    image_rot = image.rotate(rotation_angle)<br>    w_rot, h_rot = image_rot.size<br>    center=(w/2,h/2)<br>    center_rot=(w_rot/2,h_rot/2)<br>    landmarks_rot=landmarks-center<br>    landmarks_rot = np.asarray(np.dot(landmarks_rot, manual_theta_inv)[:, :2])<br>    landmarks_rot=landmarks_rot+center_rot</p><blockquote><p>manual_theta_inv是旋转矩阵.</p></blockquote><p>##图片放缩:<br>    w, h = image.size<br>    image =torchvision.transforms.Resize((self.output_size, self.output_size))(image)<br>    landmarks = landmarks * [self.output_size / w, self.output_size / h]</p><p>##图片归一化:<br>    self.mean_img=np.mean(self.imgs,axis=(-3,-2))<br>    self.std_dev_img=np.std(self.imgs,axis=(-3,-2))<br>    self.imgs=(self.imgs-self.mean_img)/self.std_dev_img</p><p>##图片转换成张量:<br>    image=torchvision.transforms.ToTensor(image)<br>    landmarks=torch.from_numpy(landmarks).float().div(img_size)</p><p>##根据一个关键点，生成一个热点图:<br>    return np.zeros((heatmap.size, heatmap.size))</p><blockquote><p>如果关键点不可见，则返回全0矩阵</p></blockquote><pre><code>x_range = [i for i in range(heatmap.size)]y_range = [i for i in range(heatmap.size)]xx, yy = np.meshgrid(x_range, y_range)d2 = (xx - keypoint[0]) ** 2 + (yy - keypoint[1]) ** 2</code></pre><blockquote><p>xx是x_range的行扩展，yy是y_range的列扩展。xx-keypoint[0]，xx中第keypoint[0]列为0。yy-keypoint[1]，yy中第keypoint[1]行为0。d2,只有keypoint坐标下的值为0。</p></blockquote><pre><code>exponent = d2 / 2.0 / sigma / sigmaheatmap = np.exp(-exponent)</code></pre><blockquote><p>heatmap中只有关键点坐标值为1，其他坐标值皆小于1。</p></blockquote><p>##根据关键点生成热点图:<br>    landmarks = landmarks * [self.heatmap_size / image.size, self.heatmap_size / image.size]<br>    for i in range(68):<br>        flag = ~np.isnan(landmarks[i, 0])<br>        heatmap=…<br>        heatmap = heatmap[np.newaxis, …]<br>        hearmaps.append(heatmap)</p><blockquote><p>flag:该关键点是否被遮挡，或者不可见。如果不可见，则landmark值为NaN。</p></blockquote><p>##测试误差</p><blockquote><p>瞳孔距离:</p></blockquote><pre><code>normDist = np.linalg.norm(np.mean(gtLandmarks[36:42], axis=0) - np.mean(gtLandmarks[42:48], axis=0))</code></pre><blockquote><p>眼角距离:</p></blockquote><pre><code>normDist = np.linalg.norm(gtLandmarks[36] - gtLandmarks[45])</code></pre><blockquote><p>边界框对角线距离:</p></blockquote><pre><code>height, width = np.max(gtLandmarks, axis=0) - np.min(gtLandmarks, axis=0)normDist = np.sqrt(width ** 2 + height ** 2)</code></pre><blockquote><p>FAN的边界框对角线距离:</p></blockquote><pre><code>height, width = np.max(gtLandmarks, axis=0) - np.min(gtLandmarks, axis=0)normDist=np.sqrt(width*height)</code></pre><blockquote><p>测试误差:</p></blockquote><pre><code>err = np.mean(np.sqrt(np.sum((gtLandmarks - ptLandmarks) ** 2, axis=1))) / normDist</code></pre><p>##左右翻转图片:</p><blockquote><p>图片左右翻转:</p></blockquote><pre><code>img=np.array(np.fliplr(img))</code></pre><blockquote><p>关键点左右翻转:</p></blockquote><pre><code>landmark[:,:,0]=img.size[1]-landmark[:,:,0]    #把关键点的坐标置以图片的x坐标中点对称</code></pre><p>##扰动:</p><blockquote><p>从正态分布随机产生一个弧度，均值为0，方差是给定的弧度</p></blockquote><pre><code>angel=np.random.normal(0,rotation_std_dev_radian)</code></pre><blockquote><p>正太分布的标准差，均值为0，随机产生偏移</p></blockquote><pre><code>offset=[np.random.normal(0,translation_std_dev_x),np.random.normal(0,translation_std_dev_y)]</code></pre><blockquote><p>随机产生放缩比例</p></blockquote><pre><code>scaling=np.random.normal(1,scale_std_dev)</code></pre><blockquote><p>旋转矩阵:</p></blockquote><pre><code>R=np.array([[np.cos(angel),-np.sin(angel)],[np.sin(angel),np.cos(angel)]])</code></pre><p>##显示68个关键点在人脸中的位置:<br>    def drawLineChart(frame,i,j):</p><pre><code>    for k in range(i,j-1):        cv2.circle(frame,(preds[k,0],preds[k,1]),2,(255,255,255),-1)        cv2.line(frame,(preds[k,0],preds[k,1]),(preds[k+1,0],preds[k+1,1]),(255,255,255),1)    cv2.circle(frame,(preds[j-1,0],preds[j-1,1]),2,(255,255,255),-1)drawLineChart(frame,0,17)drawLineChart(frame,17,22)drawLineChart(frame,22,27)drawLineChart(frame,27,31)drawLineChart(frame,31,36)drawLineChart(frame,36,42)cv2.line(frame,(preds[41,0],preds[41,1]),(preds[36,0],preds[36,1]),(255,255,255),1)drawLineChart(frame,42,48)cv2.line(frame,(preds[47,0],preds[47,1]),(preds[42,0],preds[42,1]),(255,255,255),1)drawLineChart(frame,48,60)cv2.line(frame,(preds[59,0],preds[59,1]),(preds[48,0],preds[48,1]),(255,255,255),1)drawLineChart(frame,60,68)cv2.line(frame,(preds[67,0],preds[67,1]),(preds[60,0],preds[60,1]),(255,255,255),1)</code></pre><p>##高斯图:</p><p>###高斯核:<br>    for i in range(height):<br>            for j in range(width):<br>                gauss[i][j] = amplitude <em> math.exp(-(math.pow((j + 1 - center_x) / (<br>                    sigma_horz </em> width), 2) / 2.0 + math.pow((i + 1 - center_y) / (sigma_vert * height), 2) / 2.0))</p><p>###根据高斯核，生成高斯图:<br>    image=np.zeros((256,256))<br>    point=landmark<br>    sigma=2</p><pre><code>ul = [math.floor(point[0] - 3 * sigma), math.floor(point[1] - 3 * sigma)]     #ul=[xmin-6,ymin-6]br = [math.floor(point[0] + 3 * sigma), math.floor(point[1] + 3 * sigma)]     #br=[xmax-6,ymax+6]if (ul[0] &gt; image.shape[1] or ul[1] &gt;        image.shape[0] or br[0] &lt; 1 or br[1] &lt; 1):    return imagesize = 6 * sigma + 1g = _gaussian(size)  #高斯核  13*13g_x = [int(max(1, -ul[0])), int(min(br[0], image.shape[1])) -int(max(1, ul[0])) + int(max(1, -ul[0]))]g_y = [int(max(1, -ul[1])), int(min(br[1], image.shape[0])) -int(max(1, ul[1])) + int(max(1, -ul[1]))]img_x = [int(max(1, ul[0])), int(min(br[0], image.shape[1]))]img_y = [int(max(1, ul[1])), int(min(br[1], image.shape[0]))]assert (g_x[0] &gt; 0 and g_y[1] &gt; 0)image[img_y[0] - 1:img_y[1], img_x[0] - 1:img_x[1]] = image[img_y[0] - 1:img_y[1], img_x[0] - 1:img_x[1]] + g[g_y[0] - 1:g_y[1], g_x[0] - 1:g_x[1]]#image[ymin-1:ymax,xmin-1:xmax]=image[ymin-1:ymax,xmin-1:xmax]+g[1-1:y_max-ymin+1,1-1:x_max-xmin+1]image[image &gt; 1] = 1return image</code></pre><p>##从热点图中得到关键点坐标：<br>     max, idx = torch.max(                                                                            #max:(1,68)         idx:(1,68)<br>        hm.view(hm.size(0), hm.size(1), hm.size(2) * hm.size(3)), 2)  #(1,68,65536)<br>    idx += 1<br>    preds = idx.view(idx.size(0), idx.size(1), 1).repeat(1, 1, 2).float()        #preds:(1,68,2)<br>    preds[…, 0].apply_(lambda x: (x - 1) % hm.size(3) + 1)          #  x坐标. x=idx%hm.size(3)<br>    preds[…, 1].add_(-1).div_(hm.size(2)).floor_().add_(1)          # y坐标. y=idx/hm.size(2)<br>    for i in range(preds.size(0)):         #1<br>        for j in range(preds.size(1)):         #68<br>            hm_ = hm[i, j, :]        #(256,256)<br>            pX, pY = int(preds[i, j, 0]) - 1, int(preds[i, j, 1]) - 1<br>            if pX &gt; 0 and pX &lt; 63 and pY &gt; 0 and pY &lt; 63:<br>                diff = torch.FloatTensor(<br>                    [hm_[pY, pX + 1] - hm_[pY, pX - 1],<br>                     hm_[pY + 1, pX] - hm_[pY - 1, pX]])</p><pre><code>            preds[i, j].add_(diff.sign_().mul_(.25))preds.add_(-.5)preds_orig = torch.zeros(preds.size())                                      #preds_orig:(1,68,2)if center is not None and scale is not None:    for i in range(hm.size(0)):        for j in range(hm.size(1)):            preds_orig[i, j] = transform(                preds[i, j], center, scale, hm.size(2), True)return preds, preds_orig</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结关于人脸数据预处理的函数。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>maskrcnn阅读笔记</title>
    <link href="http://yoursite.com/2018/10/30/maskrcnn%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/10/30/maskrcnn阅读笔记/</id>
    <published>2018-10-30T11:20:42.000Z</published>
    <updated>2018-11-01T08:54:19.441Z</updated>
    
    <content type="html"><![CDATA[<p>这是我阅读Facebook发布基于pytorch1.0版本的mask r cnn所做的笔记。<br><a id="more"></a> </p><p>#优化器</p><pre><code>optimizer = make_optimizer(cfg, model)                 #得到学习率为0.02,权值衰减为0.0001，冲量是0.9的SGD优化器  </code></pre><hr><pre><code>def make_optimizer(cfg, model):    params = []    for key, value in model.named_parameters():        if not value.requires_grad:                      #若值不需要梯度计算，则跳过这次循环            continue        lr = cfg.SOLVER.BASE_LR                 # 0.02              weight_decay = cfg.SOLVER.WEIGHT_DECAY            # 0.0001        if &quot;bias&quot; in key:            lr = cfg.SOLVER.BASE_LR * cfg.SOLVER.BIAS_LR_FACTOR            weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS        # 0.0001        params += [{&quot;params&quot;: [value], &quot;lr&quot;: lr, &quot;weight_decay&quot;: weight_decay}]    optimizer = torch.optim.SGD(params, lr, momentum=cfg.SOLVER.MOMENTUM)        #返回SGD优化器    return optimizer</code></pre><p>#学习率更新规则</p><pre><code>scheduler = make_lr_scheduler(cfg, optimizer)</code></pre><hr><pre><code>def make_lr_scheduler(cfg, optimizer):    return WarmupMultiStepLR(        optimizer,        cfg.SOLVER.STEPS,        cfg.SOLVER.GAMMA,        warmup_factor=cfg.SOLVER.WARMUP_FACTOR,        warmup_iters=cfg.SOLVER.WARMUP_ITERS,        warmup_method=cfg.SOLVER.WARMUP_METHOD,    )class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):    def __init__(        self,        optimizer,             #SGD        milestones,                # (60000, 80000)           gamma=0.1,       # 0.1        warmup_factor=1.0 / 3,              #  1.0/3        warmup_iters=500,        # 500        warmup_method=&quot;linear&quot;,   # &quot;linear&quot;        last_epoch=-1,    ):        if not list(milestones) == sorted(milestones):            raise ValueError(                &quot;Milestones should be a list of&quot; &quot; increasing integers. Got {}&quot;,                milestones,            )        if warmup_method not in (&quot;constant&quot;, &quot;linear&quot;):            raise ValueError(                &quot;Only &apos;constant&apos; or &apos;linear&apos; warmup_method accepted&quot;                &quot;got {}&quot;.format(warmup_method)            )        self.milestones = milestones        self.gamma = gamma        self.warmup_factor = warmup_factor        self.warmup_iters = warmup_iters        self.warmup_method = warmup_method        super(WarmupMultiStepLR, self).__init__(optimizer, last_epoch)    def get_lr(self):        warmup_factor = 1        if self.last_epoch &lt; self.warmup_iters:             if self.warmup_method == &quot;constant&quot;:                warmup_factor = self.warmup_factor            elif self.warmup_method == &quot;linear&quot;:                alpha = self.last_epoch / self.warmup_iters          # -0.002                warmup_factor = self.warmup_factor * (1 - alpha) + alpha     # 500.98        return [            base_lr* warmup_factor* self.gamma ** bisect_right(self.milestones, self.last_epoch)            for base_lr in self.base_lrs        ]</code></pre><p>#从checkpoint载入预模型</p><pre><code>checkpointer = DetectronCheckpointer(cfg, model, optimizer, scheduler, output_dir, save_to_disk)extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT)  </code></pre><hr><pre><code>def load(self, f=None):             #f=&quot;catalog://ImageNetPretrained/MSRA/R-50&quot;   if self.has_checkpoint():            #判断checkpoint文件是否存在       # override argument with existing checkpoint       f = self.get_checkpoint_file()        #读取checkpoint文件   if not f:                                     #如果checkpoint不存在，则从头开始初始化模型，并返回{}       # no checkpoint could be found       self.logger.info(&quot;No checkpoint found. Initializing model from scratch&quot;)       return {}   self.logger.info(&quot;Loading checkpoint from {}&quot;.format(f))   checkpoint = self._load_file(f)         self._load_model(checkpoint)                 #载入模型   if &quot;optimizer&quot; in checkpoint and self.optimizer:         #读取优化器       self.logger.info(&quot;Loading optimizer from {}&quot;.format(f))       self.optimizer.load_state_dict(checkpoint.pop(&quot;optimizer&quot;))   if &quot;scheduler&quot; in checkpoint and self.scheduler:            #读取学习率更新规则       self.logger.info(&quot;Loading scheduler from {}&quot;.format(f))       self.scheduler.load_state_dict(checkpoint.pop(&quot;scheduler&quot;))   # return any further checkpoint data   return checkpoint</code></pre><p><span id="1"></span></p><p>#载入数据</p><pre><code>data_loader = make_data_loader(cfg,is_train=True,is_distributed=distributed,start_iter=arguments[&quot;iteration&quot;],)</code></pre><hr><pre><code>def make_data_loader(cfg, is_train=True, is_distributed=False, start_iter=0):    num_gpus = get_world_size()      # 1    if is_train:        images_per_batch = cfg.SOLVER.IMS_PER_BATCH         # 16        assert (            images_per_batch % num_gpus == 0        ), &quot;SOLVER.IMS_PER_BATCH ({}) must be divisible by the number &quot;        &quot;of GPUs ({}) used.&quot;.format(images_per_batch, num_gpus)        images_per_gpu = images_per_batch // num_gpus               # 16        shuffle = True        num_iters = cfg.SOLVER.MAX_ITER                 # 90000    else:        images_per_batch = cfg.TEST.IMS_PER_BATCH            # 8        assert (            images_per_batch % num_gpus == 0        ), &quot;TEST.IMS_PER_BATCH ({}) must be divisible by the number &quot;        &quot;of GPUs ({}) used.&quot;.format(images_per_batch, num_gpus)        images_per_gpu = images_per_batch // num_gpus          # 8        shuffle = False if not is_distributed else True        num_iters = None        start_iter = 0    if images_per_gpu &gt; 1:        logger = logging.getLogger(__name__)        logger.warning(            &quot;When using more than one image per GPU you may encounter &quot;            &quot;an out-of-memory (OOM) error if your GPU does not have &quot;            &quot;sufficient memory. If this happens, you can reduce &quot;            &quot;SOLVER.IMS_PER_BATCH (for training) or &quot;            &quot;TEST.IMS_PER_BATCH (for inference). For training, you must &quot;            &quot;also adjust the learning rate and schedule length according &quot;            &quot;to the linear scaling rule. See for example: &quot;            &quot;https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14&quot;        )    # group images which have similar aspect ratio. In this case, we only    # group in two cases: those with width / height &gt; 1, and the other way around,    # but the code supports more general grouping strategy    aspect_grouping = [1] if cfg.DATALOADER.ASPECT_RATIO_GROUPING else []            #True    paths_catalog = import_file(        &quot;maskrcnn_benchmark.config.paths_catalog&quot;, cfg.PATHS_CATALOG, True    )    DatasetCatalog = paths_catalog.DatasetCatalog    dataset_list = cfg.DATASETS.TRAIN if is_train else cfg.DATASETS.TEST    transforms = build_transforms(cfg, is_train)    datasets = build_dataset(dataset_list, transforms, DatasetCatalog, is_train)    data_loaders = []    for dataset in datasets:        sampler = make_data_sampler(dataset, shuffle, is_distributed)        batch_sampler = make_batch_data_sampler(            dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter        )        collator = BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)        num_workers = cfg.DATALOADER.NUM_WORKERS        data_loader = torch.utils.data.DataLoader(            dataset,            num_workers=num_workers,            batch_sampler=batch_sampler,            collate_fn=collator,        )        data_loaders.append(data_loader)    if is_train:        # during training, a single (possibly concatenated) data_loader is returned        assert len(data_loaders) == 1        return data_loaders[0]    return data_loaders</code></pre><p>*<a href="#1">1.单反入门</a></p><h2 id="1">1. 单反入门</h2><p>熟练掌握摄影三要素：对焦、曝光、光圈。</p><h2 id="1.1">1.1 对焦</h2><p>对焦决定你的相片的清晰度。</p><h2 id="1.2">1.2 曝光</h2><p>不同的曝光会让照片呈现不一样的效果。</p><h2 id="1.3">1.3 光圈</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是我阅读Facebook发布基于pytorch1.0版本的mask r cnn所做的笔记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
</feed>
